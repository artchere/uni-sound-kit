# Universal Sound Kit
Сервис для обучения и инференса моделей в рамках задач классификации аудио.

### Модели:
На борту репозитория внутри `cores/nn_modules` собраны вспомогательные модули и архитектуры (в большинстве - на одномерных слоях),
работающие как с сырым аудио, так и с его частотно-временным представлением (например, БПФ):
- `extractor` - модуль извлечения частотно-временных признаков
- `classifier` - универсальный выходной модуль (head) для встраивания в любой эмбеддер, включает в себя голову на
полносвязных слоях, а также связку LSTM + Temporal Attention; данный модуль встроен в большинство архитектур сервиса
- `loss` - модуль с конфигурируемой функцией потерь - Cross Entropy или
F1 (пока поддерживается только бинарная классификация)
- `cnnt` - CNN+Transformer (частотно-временные признаки), универсальная сеть
- `ecapa_tdnn` - адаптация/мод архитектуры ECAPA TDNN (частотно-временные признаки), для задач классификации звуков
или формирования эмбеддингов
- `m5net` - адаптация/мод архитектуры M5 (RAW аудио), для задач классификации звуков или формирования эмбеддингов
- `matchbox` - torch-имплементация сети (частотно-временные признаки), для задач KWS
- `soundnet` - адаптация одноимённой архитектуры (RAW аудио), для задач классификации звуков
или формирования эмбеддингов
- `speaknet` - адаптация/мод архитектуры из примера на официальном сайте keras по верификации дикторов
(частотно-временные признаки), для задач классификации звуков или формирования эмбеддингов
- `tc_resnet` - адаптация/мод TC-ResNet14 (частотно-временные признаки), для задач KWS
- `uit` - адаптация/мод UIT Mobile (частотно-временные признаки), для задач KWS
- `voxseg` - torch-имплементация сети (частотно-временные признаки), для задач VAD

Экстрактор признаков для FxT-домена (внутри `extractor`) реализован на базе nn.Module
и автоматически встраивается в модель так же как и классификационный модуль (в случае если тело модели предполагает работу с FxT); доступные типы:
- `melspec` - mel-scaled STFT с нормализацией
- `mfcc` - мел-частотные кепстральные коэффициенты с нормализацией
- `spectral` - стек из RMS, SFM, Contrast, F0 и прочих спектральных фичей (пока без поддержки GPU)

Конфигурация экстрактора позволяет настроить использование preemphasis (ФВЧ 1-го порядка), порядок производной (1 и 2 - порядок, 0 - без дифференцирования),
задать разрешение по времени и частоте для БПФ, число DCT-коэффициентов и частотных фильтров.

Внутри `app/base` лежат скрипты для инференса - потоковый режим на файле, потоковый режим на сигнале с физического устройства (например - микрофона), ws-клиент и сервер.
Внутри `app` расположены скрипты для kws-сервера на Fastapi (вспомогательный функционал: `app/services` и `app/routers`).

### Установка и запуск

Для работы сервиса необходимо установить `Docker` и `docker-compose`:
```bash
sudo apt-get update
sudo apt-get install \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg-agent \
    software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo apt-key fingerprint 0EBFCD88
sudo add-apt-repository \
    "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
    $(lsb_release -cs) \
    stable"
sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io
sudo usermod -aG docker $(whoami)
sudo curl -L "https://github.com/docker/compose/releases/download/1.25.5/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
```

Для билда сервиса выполните команду:
```
sudo docker-compose build
```

Для запуска и перезапуска сервиса выполните команду:
```
sudo docker-compose up -d --force-recreate
```
